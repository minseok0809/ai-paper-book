# AI Paper
<br>

|    | Title                                                                                                         | Journal/Conference  | Date       | Author                      | Link                                                                                                                                                  |
| -- | ------------------------------------------------------------------------------------------------------------- | ------------------- | ---------- | --------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1  | Adaptive Mixtures of Local Experts                                                                            | MIT Press 1991      | 1991-03-01 | Robert A. Jacobs et al      | [Link](https://ieeexplore.ieee.org/abstract/document/6797059)                                                                                         |
| 2  | BLEU: a method for automatic evaluation of machine translation                                                | ACL 2002            | 2002-07-01 | Kishore Papineni et al      | [Link](https://dl.acm.org/doi/10.3115/1073083.1073135)                                                                                                |
| 3  | Model Compression                                                                                             | ACM SIGKDD 2006     | 2006-08-20 | Cristian Bucil˘a et al      | [Link](https://dl.acm.org/doi/abs/10.1145/1150402.1150464)                                                                                            |
| 4  | Large-Scale Distributed Language Modeling                                                                     | IEEE 2007           | 2007-04-05 | Ahmad Emami et al           | [Link](https://ieeexplore.ieee.org/document/4218031)                                                                                                  |
| 5  | Large Language Models in Machine Translation                                                                  | EMNLP 2007          | 2007-06-01 | Gloria Brown Wright et al   | [Link](https://aclanthology.org/D07-1090/)                                                                                                            |
| 6  | Student-Centered Learning in Higher Education                                                                 |                     | 2011-01-01 | Thorsten Brants et al       | [Link](https://files.eric.ed.gov/fulltext/EJ938583.pdf)                                                                                               |
| 7  | Efficient Estimation of Word Representations in Vector Space                                                  |                     | 2013-01-16 | Tomas Mikolov et al         | [Link](http://arxiv.org/abs/1301.3781v3)                                                                                                              |
| 8  | Linguistic Regularities in Continuous Space Word Representations                                              | NAACL 2013          | 2013-06-01 | Tomas Mikolov et al         | [Link](https://aclanthology.org/N13-1090/)                                                                                                            |
| 9  | Dropout: A Simple Way to Prevent Neural Networks from Overfitting                                             | JMLR 2014           | 2014-01-01 | Nitish Srivastava et al     | [Link](https://ieeexplore.ieee.org/abstract/document/6797059)                                                                                         |
| 10 | Neural Machine Translation by Jointly Learning to Align and Translate                                         | ICLR 2015          | 2014-09-01 | Dzmitry Bahdanau et al      | [Link](http://arxiv.org/abs/1409.0473v7)                                                                                                              |
| 11 | Sequence to Sequence Learning with Neural Networks                                                            | NeurIPS 2014        | 2014-09-10 | Ilya Sutskever et al        | [Link](http://arxiv.org/abs/1409.3215v3)                                                                                                              |
| 12 | Distilling the Knowledge in a Neural Network                                                                  | NIPS 2014          | 2015-03-09 | Geoffrey Hinton et al       | [Link](http://arxiv.org/abs/1503.02531v1)                                                                                                             |
| 13 | Neural Machine Translation of Rare Words with Subword Units                                                   | ACL 2016           | 2015-08-31 | Rico Sennrich et al         | [Link](http://arxiv.org/abs/1508.07909v5)                                                                                                             |
| 14 | Adaptive Computation Time for Recurrent Neural Networks                                                       |                     | 2016-03-29 | Alex Graves et al           | [Link](http://arxiv.org/abs/1603.08983v6)                                                                                                             |
| 15 | Building Machines That Learn and Think Like People                                                            |                     | 2016-04-01 | Brenden M. Lake et al       | [Link](http://arxiv.org/abs/1604.00289v3)                                                                                                             |
| 16 | Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation            |                     | 2016-09-26 | Yonghui Wu et al            | [Link](http://arxiv.org/abs/1609.08144v2)                                                                                                             |
| 17 | Overcoming catastrophic forgetting in neural networks                                                         |                     | 2016-12-02 | James Kirkpatrick et al     | [Link](http://arxiv.org/abs/1612.00796v2)                                                                                                             |
| 18 | Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks                                             | ICML 2017          | 2017-03-09 | Chelsea Finn et al          | [Link](http://arxiv.org/abs/1703.03400v3)                                                                                                             |
| 19 | Attention Is All You Need                                                                                     | NeurIPS 2017        | 2017-06-12 | Ashish Vaswani et al        | [Link](http://arxiv.org/abs/1706.03762v5)                                                                                                             |
| 20 | Optimization as A Model for Few-shot Learning                                                                 | ICLR 2017          | 2017-07-22 | Sachin Ravi et al           | [Link](https://openreview.net/forum?id=rJY0-Kcll)                                                                                                     |
| 21 | Adversarial Examples for Evaluating Reading Comprehension Systems                                             | EMNLP 2017         | 2017-07-23 | Robin Jia et al             | [Link](http://arxiv.org/abs/1707.07328v1)                                                                                                             |
| 22 | BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks                                        |                     | 2017-09-06 | Surat Teerapittayanon et al | [Link](http://arxiv.org/abs/1709.01686v1)                                                                                                             |
| 23 | Deep contextualized word representations                                                                      | NAACL 2018         | 2018-02-15 | Matthew E. Peters et al     | [Link](http://arxiv.org/abs/1802.05365v2)                                                                                                             |
| 24 | GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding                         | ICLR 2019          | 2018-04-20 | Alex Wang et al             | [Link](http://arxiv.org/abs/1804.07461v3)                                                                                                             |
| 25 | Do CIFAR-10 Classifiers Generalize to CIFAR-10?                                                               |                     | 2018-06-01 | Benjamin Recht et al        | [Link](http://arxiv.org/abs/1806.00451v1)                                                                                                             |
| 26 | SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing | EMNLP 2018          | 2018-08-19 | Taku Kudo et al             | [Link](http://arxiv.org/abs/1808.06226v1)                                                                                                             |
| 27 | BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding                              | ACL 2019           | 2018-10-11 | Jacob Devlin et al          | [Link](http://arxiv.org/abs/1810.04805v2)                                                                                                             |
| 28 | Improved Knowledge Distillation via Teacher Assistant                                                         | AAAI 2020          | 2019-02-09 | Seyed-Iman Mirzadeh et al   | [Link](http://arxiv.org/abs/1902.03393v2)                                                                                                             |
| 29 | Language Models are Unsupervised Multitask Learners                                                           |                     | 2019-06-01 | Alec Radford et al          | [Link](https://www.semanticscholar.org/paper/Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu/9405cc0d6169988371b2755e573cc28650d14dfe) |
| 30 | Patient Knowledge Distillation for BERT Model Compression                                                     | EMNLP 2019         | 2019-08-25 | Siqi Sun et al              | [Link](http://arxiv.org/abs/1908.09355v1)                                                                                                             |
| 31 | DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter                                 | NeurIPS 2019        | 2019-10-02 | Victor Sanh et al           | [Link](http://arxiv.org/abs/1910.01108v4)                                                                                                             |
| 32 | MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers            | NeurIPS 2020        | 2020-02-25 | Wenhui Wang et al           | [Link](http://arxiv.org/abs/2002.10957v2)                                                                                                             |
| 33 | FastBERT: a Self-distilling BERT with Adaptive Inference Time                                                 | ACL 2020           | 2020-04-05 | Weijie Liu et al            | [Link](http://arxiv.org/abs/2004.02178v2)                                                                                                             |
| 34 | Reliable Post hoc Explanations: Modeling Uncertainty in Explainability                                        | NeurIPS 2021        | 2020-08-11 | Dylan Slack et al           | [Link](http://arxiv.org/abs/2008.05030v4)                                                                                                             |
| 35 | MiniLMv2: Multi-Head Self-Attention Relation Distillation for Compressing Pretrained Transformers             | ACL 2021 (Findings) | 2020-12-31 | Wenhui Wang et al           | [Link](http://arxiv.org/abs/2012.15828v2)                                                                                                             |
| 36 | Ensemble deep learning: A review                                                                              | AAAI 2022          | 2021-04-06 | M. A. Ganaie et al          | [Link](http://arxiv.org/abs/2104.02395v3)                                                                                                             |
| 37 | BERT Learns to Teach: Knowledge Distillation with Meta Learning                                               | ACL 2022           | 2021-06-08 | Wangchunshu Zhou et al      | [Link](http://arxiv.org/abs/2106.04570v3)                                                                                                             |
| 38 | A Survey on Model Compression and Acceleration for Pretrained Language Models                                 | AAAI 2023          | 2022-02-15 | Canwen Xu et al             | [Link](http://arxiv.org/abs/2202.07105v2)                                                                                                             |

<br><br><br><br>

# AI Book
<br>

|   | Title                                                                                                 | Author                   | Publisher               | Year |
| - | ----------------------------------------------------------------------------------------------------- | ------------------------ | ----------------------- | ---- |
| 1 | Natural Language Processing with PyTorch: Build Intelligent Language Applications Using Deep Learning | Delip Rao, Brian McMahan | O'Reilly Media         | 2019 |
| 2 | Interpretable Machine Learning: A Guide for Making Black Box Models Explainable                       | Christoph Molnar         | Independently published | 2022 |

<br><br><br><br>

# Future Work
<br><b>Google Schloar Crawler</b>
<br>What's recent paper cited by the paper

<br><b>AI Paper</b>
<br>Theme Column (Next Link Column)

<br><br><br><br>

