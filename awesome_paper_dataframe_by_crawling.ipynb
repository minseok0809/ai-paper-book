{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Awesome Paper Dataframe by Crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "import requests\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas.io.formats.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_page_soup(link):\n",
    "\n",
    "    target = link\n",
    "    response = requests.get(target)\n",
    "    page = str(response.content)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "     \n",
    "    return page, soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_awesome_paper_df_type1(soup, link):\n",
    "\n",
    "    awesome_paper_df = pd.DataFrame({'Title':[0],\n",
    "                                'Journal/Conference':[0],\n",
    "                                'Year':[0], \n",
    "                                'Author':[0],\n",
    "                                'ID/Link':[0],\n",
    "                                'Source':[0]})\n",
    "    \n",
    "    li = soup.select(\"li\")\n",
    "    li_texts = []\n",
    "    for li_text in li:\n",
    "        li_text = str(li_text)\n",
    "        if 'class=' not in str(li_text) and 'href=' not in li_text:\n",
    "            li_text = li_text[li_text.find('<li>')+4 : li_text.find(\"</li>\")]\n",
    "            li_texts.append(li_text)\n",
    "        \n",
    "    for idx, li_text in enumerate(li_texts):\n",
    "\n",
    "        li_text_split = li_text.split('.')\n",
    "    \n",
    "        paper_title = li_text_split[0]\n",
    "        paper_title = re.sub(r\"\\[.*?\\]|\\<.*?\\>\", \"\", paper_title)\n",
    "\n",
    "        if ']' in paper_title and '[' not in paper_title:\n",
    "            paper_title  = re.sub(r\"].*?\", \"\", paper_title)  \n",
    "\n",
    "        if len(li_text_split) > 1:\n",
    "            paper_author = li_text_split[1]\n",
    "            if 'et al.' not in paper_author:\n",
    "                paper_author = \"\"\n",
    "        else:\n",
    "            paper_author = \"\"\n",
    "\n",
    "        paper_journal_conf = re.search(r'[A-Z ]+[0-9]+[0-9]+[0-9]+[0-9]', li_text)\n",
    "\n",
    "        if paper_journal_conf != None:\n",
    "            paper_journal_conf = paper_journal_conf.group().strip()\n",
    "            if len(paper_journal_conf) == 4 and int(paper_journal_conf) > 2100:\n",
    "                paper_journal_conf = \"\"\n",
    "            else:\n",
    "                paper_year = re.sub(r'[^0-9]', '', paper_journal_conf)     \n",
    "        else:\n",
    "            paper_journal_conf = \"\"\n",
    "            paper_year = \"\"\n",
    "        \n",
    "        paper_id = re.search(r'[0-9]+[0-9]+[0-9]+[0-9.]+[0-9]+[0-9]+[0-9]+[0-9]+[0-9]', li_text)\n",
    "        if paper_id != None:\n",
    "            paper_id = paper_id.group().strip()\n",
    "        else:\n",
    "            paper_id = \"\"\n",
    "    \n",
    "        if len(paper_title) > 5:    \n",
    "            awesome_paper_df.loc[idx] = [paper_title, \n",
    "                                    paper_journal_conf,\n",
    "                                    paper_year, \n",
    "                                    paper_author,\n",
    "                                    paper_id,\n",
    "                                    link]\n",
    "        \n",
    "    return awesome_paper_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_awesome_paper_df_type2(soup, link):\n",
    "\n",
    "    awesome_paper_df = pd.DataFrame({'Title':[0],\n",
    "                                'Journal/Conference':[0],\n",
    "                                'Year':[0], \n",
    "                                'Author':[0],\n",
    "                                'ID/Link':[0],\n",
    "                                'Source':[0]})\n",
    "    \n",
    "    li = soup.select(\"li\")\n",
    "    li_texts = []\n",
    "    for li_text in li:\n",
    "        li_text = str(li_text)\n",
    "        if '<p dir=\"auto\">' in str(li_text) :\n",
    "            li_text = li_text[li_text.find('<strong>')+8 : li_text.find(\"</strong>\")]\n",
    "            li_texts.append(li_text)\n",
    "        \n",
    "    for idx, li_text in enumerate(li_texts):\n",
    "\n",
    "        li_text_split = li_text.split(',')\n",
    "    \n",
    "        paper_title = li_text_split[0]\n",
    "        paper_author = \"\"\n",
    "\n",
    "        paper_journal_conf = re.search(r'[A-Z ]+[0-9]+[0-9]+[0-9]+[0-9]', li_text)\n",
    "        if paper_journal_conf != None:\n",
    "            paper_journal_conf = paper_journal_conf.group().strip()\n",
    "            if len(paper_journal_conf) == 4 and int(paper_journal_conf) > 2100:\n",
    "                paper_journal_conf = \"\"\n",
    "            else:\n",
    "                paper_year = re.sub(r'[^0-9]', '', paper_journal_conf)\n",
    "        else:\n",
    "            paper_journal_conf = \"\"\n",
    "            paper_year = \"\"\n",
    "        \n",
    "\n",
    "        paper_id = re.search(r'[0-9]+[0-9]+[0-9]+[0-9.]+[0-9]+[0-9]+[0-9]+[0-9]+[0-9]', li_text)\n",
    "        if paper_id != None:\n",
    "            paper_id = paper_id.group().strip()\n",
    "        else:\n",
    "            paper_id = \"\"\n",
    "\n",
    "        if len(paper_title) > 5:    \n",
    "            awesome_paper_df.loc[idx] = [paper_title, \n",
    "                                    paper_journal_conf,\n",
    "                                    paper_year, \n",
    "                                    paper_author,\n",
    "                                    paper_id,\n",
    "                                    link]        \n",
    "    return awesome_paper_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_awesome_paper_df_type3(soup, link):\n",
    "\n",
    "    awesome_paper_df = pd.DataFrame({'Title':[0],\n",
    "                                'Journal/Conference':[0],\n",
    "                                'Year':[0], \n",
    "                                'Author':[0],\n",
    "                                'ID/Link':[0],\n",
    "                                'Source':[0]})\n",
    "    \n",
    "    li = soup.select(\"li\")\n",
    "    li_texts = []\n",
    "    for li_text in li:\n",
    "        li_text = str(li_text)\n",
    "        if 'class=' not in li_text and 'href=' in li_text:\n",
    "            li_texts.append(li_text)\n",
    "        \n",
    "    for idx, li_text in enumerate(li_texts):\n",
    "\n",
    "        paper_title = li_text[li_text.find('\"nofollow\">')+4 : li_text.find(\"</a>\")]\n",
    "        paper_title = paper_title[paper_title.find('\">')+2 : ]\n",
    "\n",
    "        li_text_split1 = li_text.split(\",\")[-1]\n",
    "        li_text_split2 = li_text.split(\",\")[-2]\n",
    "\n",
    "        if \"href=\" not in li_text_split1:\n",
    "            paper_journal_conf = li_text_split1\n",
    "\n",
    "        elif \"href=\" in li_text_split1:\n",
    "            paper_journal_conf = li_text_split2\n",
    "\n",
    "        paper_journal_conf = re.search(r'[A-Z ]+[0-9]+[0-9]+[0-9]+[0-9]', paper_journal_conf)\n",
    "        if paper_journal_conf != None:\n",
    "            paper_journal_conf = paper_journal_conf.group().strip()\n",
    "            if len(paper_journal_conf) == 4 and int(paper_journal_conf) > 2100:\n",
    "                paper_journal_conf = \"\"\n",
    "            else:\n",
    "                paper_year = re.sub(r'[^0-9]', '', paper_journal_conf)\n",
    "        else:\n",
    "            paper_journal_conf = \"\"\n",
    "            paper_year = \"\"\n",
    "\n",
    "        paper_author = ', '.join(li_text.split(\",\")[1:-1])\n",
    "        paper_id = li_text[li_text.find('href=\">')+11 : li_text.find('\" rel=\"')]\n",
    "        paper_id = paper_id[paper_id.find('=\"')+2 :]\n",
    "\n",
    "        if \"github\" not in paper_title and len(paper_title) > 5:\n",
    "            awesome_paper_df.loc[idx] = [paper_title, \n",
    "                                    paper_journal_conf,\n",
    "                                    paper_year, \n",
    "                                    paper_author,\n",
    "                                    paper_id,\n",
    "                                    link]\n",
    "        \n",
    "    return awesome_paper_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_awesome_paper_df(awesome_paper_df_list):\n",
    "\n",
    "    awesome_paper_df = pd.concat(awesome_paper_df_list)\n",
    "    awesome_paper_df.drop_duplicates(subset='Title', inplace=True)\n",
    "    awesome_paper_df = awesome_paper_df.sort_values('Year', ascending=True).reset_index().drop(['index'], axis='columns')\n",
    "\n",
    "    return awesome_paper_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_awesome_nlp_paper_df(awesome_paper_df, conference_list):\n",
    "\n",
    "    awesome_nlp_paper_df_list = []\n",
    "\n",
    "    for conference in conference_list:\n",
    "        awesome_nlp_paper_df = awesome_paper_df[(awesome_paper_df['Journal/Conference'].str.contains(conference))]\n",
    "        awesome_nlp_paper_df_list.append(awesome_nlp_paper_df)\n",
    "\n",
    "    awesome_nlp_paper_df = pd.concat(awesome_nlp_paper_df_list)\n",
    "    awesome_nlp_paper_df.drop_duplicates(subset='Title', inplace=True)\n",
    "    awesome_nlp_paper_df = awesome_nlp_paper_df.sort_values('Year', ascending=True).reset_index().drop(['index'], axis='columns')\n",
    "\n",
    "    return awesome_nlp_paper_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://github.com/FLHonker/Awesome-Knowledge-Distillation\"\n",
    "page, soup = make_page_soup(link)\n",
    "awesome_paper_df1 = make_awesome_paper_df_type1(soup, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://github.com/DefangChen/Knowledge-Distillation-Paper\"\n",
    "page, soup = make_page_soup(link)\n",
    "awesome_paper_df2 = make_awesome_paper_df_type2(soup, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://github.com/lhyfst/knowledge-distillation-papers\"\n",
    "page, soup = make_page_soup(link)\n",
    "awesome_paper_df3 = make_awesome_paper_df_type3(soup, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "awesome_paper_df_list = [awesome_paper_df1, awesome_paper_df2, awesome_paper_df3]\n",
    "awesome_paper_df = make_awesome_paper_df(awesome_paper_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "conference_list = ['NeurlPS', 'ICML', 'ICLR', 'AAAI', 'IJCAI', 'ACM', 'IEEE', 'IJCAI', 'AISTATS',\n",
    "                    'ACL', 'EMNLP', 'NAACL', 'EACL', 'AACL', 'COLING', 'WMT', 'IJCNLP', 'HLT']\n",
    "awesome_nlp_paper_df = make_awesome_nlp_paper_df(awesome_paper_df, conference_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Journal/Conference</th>\n",
       "      <th>Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>ID/Link</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Distilling the knowledge in a neural network</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1503.02531</td>\n",
       "      <td>https://github.com/FLHonker/Awesome-Knowledge-Distillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Distilled Hierarchical Neural Ensembles with Adaptive Inference Cost</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2003.01474</td>\n",
       "      <td>https://github.com/FLHonker/Awesome-Knowledge-Distillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Distilling Knowledge from Ensembles of Acoustic Models for Joint CTC-Attention End-to-End Speech Recognition</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2005.09310</td>\n",
       "      <td>https://github.com/FLHonker/Awesome-Knowledge-Distillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Collaborative Learning for Faster StyleGAN Embedding</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2007.01758</td>\n",
       "      <td>https://github.com/FLHonker/Awesome-Knowledge-Distillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Group Knowledge Transfer: Collaborative Training of Large CNNs on the Edge</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2007.14513</td>\n",
       "      <td>https://github.com/FLHonker/Awesome-Knowledge-Distillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>Adaptive Multi-Teacher Knowledge Distillation with Meta-Learning</td>\n",
       "      <td>ICME 2023</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/DefangChen/Knowledge-Distillation-Paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>Customizing Synthetic Data for Data-Free Student Learning</td>\n",
       "      <td>ICME 2023</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/DefangChen/Knowledge-Distillation-Paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>Holistic Weighted Distillation for Semantic Segmentation</td>\n",
       "      <td>ICME 2023</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/DefangChen/Knowledge-Distillation-Paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>Accelerating Diffusion Sampling with Classifier-based Feature Distillation</td>\n",
       "      <td>ICME 2023</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/DefangChen/Knowledge-Distillation-Paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Disjoint Masking with Joint Distillation for Efficient Masked Image Modeling</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>Xin Ma,  Chang Liu,  Chunyu Xie,  Long Ye,  Yafeng Deng,  Xiangyang Ji,  arXiv 2023</td>\n",
       "      <td>https://arxiv.org/abs/2301.00230</td>\n",
       "      <td>https://github.com/lhyfst/knowledge-distillation-papers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>693 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                            Title   \n",
       "0                                                                    Distilling the knowledge in a neural network  \\\n",
       "1                                            Distilled Hierarchical Neural Ensembles with Adaptive Inference Cost   \n",
       "2    Distilling Knowledge from Ensembles of Acoustic Models for Joint CTC-Attention End-to-End Speech Recognition   \n",
       "3                                                            Collaborative Learning for Faster StyleGAN Embedding   \n",
       "4                                      Group Knowledge Transfer: Collaborative Training of Large CNNs on the Edge   \n",
       "..                                                                                                            ...   \n",
       "688                                              Adaptive Multi-Teacher Knowledge Distillation with Meta-Learning   \n",
       "689                                                     Customizing Synthetic Data for Data-Free Student Learning   \n",
       "690                                                      Holistic Weighted Distillation for Semantic Segmentation   \n",
       "691                                    Accelerating Diffusion Sampling with Classifier-based Feature Distillation   \n",
       "692                                  Disjoint Masking with Joint Distillation for Efficient Masked Image Modeling   \n",
       "\n",
       "    Journal/Conference  Year   \n",
       "0                             \\\n",
       "1                              \n",
       "2                              \n",
       "3                              \n",
       "4                              \n",
       "..                 ...   ...   \n",
       "688          ICME 2023  2023   \n",
       "689          ICME 2023  2023   \n",
       "690          ICME 2023  2023   \n",
       "691          ICME 2023  2023   \n",
       "692               2023  2023   \n",
       "\n",
       "                                                                                   Author   \n",
       "0                                                                                          \\\n",
       "1                                                                                           \n",
       "2                                                                                           \n",
       "3                                                                                           \n",
       "4                                                                                           \n",
       "..                                                                                    ...   \n",
       "688                                                                                         \n",
       "689                                                                                         \n",
       "690                                                                                         \n",
       "691                                                                                         \n",
       "692   Xin Ma,  Chang Liu,  Chunyu Xie,  Long Ye,  Yafeng Deng,  Xiangyang Ji,  arXiv 2023   \n",
       "\n",
       "                              ID/Link   \n",
       "0                          1503.02531  \\\n",
       "1                          2003.01474   \n",
       "2                          2005.09310   \n",
       "3                          2007.01758   \n",
       "4                          2007.14513   \n",
       "..                                ...   \n",
       "688                                     \n",
       "689                                     \n",
       "690                                     \n",
       "691                                     \n",
       "692  https://arxiv.org/abs/2301.00230   \n",
       "\n",
       "                                                         Source  \n",
       "0    https://github.com/FLHonker/Awesome-Knowledge-Distillation  \n",
       "1    https://github.com/FLHonker/Awesome-Knowledge-Distillation  \n",
       "2    https://github.com/FLHonker/Awesome-Knowledge-Distillation  \n",
       "3    https://github.com/FLHonker/Awesome-Knowledge-Distillation  \n",
       "4    https://github.com/FLHonker/Awesome-Knowledge-Distillation  \n",
       "..                                                          ...  \n",
       "688  https://github.com/DefangChen/Knowledge-Distillation-Paper  \n",
       "689  https://github.com/DefangChen/Knowledge-Distillation-Paper  \n",
       "690  https://github.com/DefangChen/Knowledge-Distillation-Paper  \n",
       "691  https://github.com/DefangChen/Knowledge-Distillation-Paper  \n",
       "692     https://github.com/lhyfst/knowledge-distillation-papers  \n",
       "\n",
       "[693 rows x 6 columns]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "awesome_paper_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Journal/Conference</th>\n",
       "      <th>Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>ID/Link</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FitNets: Hints for Thin Deep Nets</td>\n",
       "      <td>ICLR 2015</td>\n",
       "      <td>2015</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/DefangChen/Knowledge-Distillation-Paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harnessing deep neural networks with logical rules</td>\n",
       "      <td>ACL 2016</td>\n",
       "      <td>2016</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/FLHonker/Awesome-Knowledge-Distillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unifying distillation and privileged information</td>\n",
       "      <td>ICLR 2016</td>\n",
       "      <td>2016</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/FLHonker/Awesome-Knowledge-Distillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Face model compression by distilling knowledge from neurons</td>\n",
       "      <td>AAAI 2016</td>\n",
       "      <td>2016</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/FLHonker/Awesome-Knowledge-Distillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer</td>\n",
       "      <td>ICLR 2017</td>\n",
       "      <td>2017</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/FLHonker/Awesome-Knowledge-Distillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Cross-Task Knowledge Distillation in Multi-Task Recommendation</td>\n",
       "      <td>AAAI 2022</td>\n",
       "      <td>2022</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/FLHonker/Awesome-Knowledge-Distillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Revisiting Label Smoothing and Knowledge Distillation Compatibility: What was Missing?</td>\n",
       "      <td>ICML 2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>Keshigeyan Chandrasegaran,  Ngoc-Trung Tran,  Yunqing Zhao,  Ngai-Man Cheung</td>\n",
       "      <td>https://proceedings.mlr.press/v162/chandrasegaran22a/chandrasegaran22a.pdf</td>\n",
       "      <td>https://github.com/lhyfst/knowledge-distillation-papers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Consistency Models</td>\n",
       "      <td>ICML 2023</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/DefangChen/Knowledge-Distillation-Paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Curriculum Temperature for Knowledge Distillation</td>\n",
       "      <td>AAAI 2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>Zheng Li,  Xiang Li,  Lingfeng Yang,  Borui Zhao,  Renjie Song,  Lei Luo,  Jun Li,  Jian Yang,  AAAI 2023</td>\n",
       "      <td>https://arxiv.org/abs/2211.16231</td>\n",
       "      <td>https://github.com/lhyfst/knowledge-distillation-papers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Fast Sampling of Diffusion Models via Operator Learning</td>\n",
       "      <td>ICML 2023</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/DefangChen/Knowledge-Distillation-Paper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                     Title   \n",
       "0                                                                                        FitNets: Hints for Thin Deep Nets  \\\n",
       "1                                                                       Harnessing deep neural networks with logical rules   \n",
       "2                                                                         Unifying distillation and privileged information   \n",
       "3                                                              Face model compression by distilling knowledge from neurons   \n",
       "4    Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer   \n",
       "..                                                                                                                     ...   \n",
       "138                                                         Cross-Task Knowledge Distillation in Multi-Task Recommendation   \n",
       "139                                 Revisiting Label Smoothing and Knowledge Distillation Compatibility: What was Missing?   \n",
       "140                                                                                                     Consistency Models   \n",
       "141                                                                      Curriculum Temperature for Knowledge Distillation   \n",
       "142                                                                Fast Sampling of Diffusion Models via Operator Learning   \n",
       "\n",
       "    Journal/Conference  Year   \n",
       "0            ICLR 2015  2015  \\\n",
       "1             ACL 2016  2016   \n",
       "2            ICLR 2016  2016   \n",
       "3            AAAI 2016  2016   \n",
       "4            ICLR 2017  2017   \n",
       "..                 ...   ...   \n",
       "138          AAAI 2022  2022   \n",
       "139          ICML 2022  2022   \n",
       "140          ICML 2023  2023   \n",
       "141          AAAI 2023  2023   \n",
       "142          ICML 2023  2023   \n",
       "\n",
       "                                                                                                         Author   \n",
       "0                                                                                                                \\\n",
       "1                                                                                                                 \n",
       "2                                                                                                                 \n",
       "3                                                                                                                 \n",
       "4                                                                                                                 \n",
       "..                                                                                                          ...   \n",
       "138                                                                                                               \n",
       "139                                Keshigeyan Chandrasegaran,  Ngoc-Trung Tran,  Yunqing Zhao,  Ngai-Man Cheung   \n",
       "140                                                                                                               \n",
       "141   Zheng Li,  Xiang Li,  Lingfeng Yang,  Borui Zhao,  Renjie Song,  Lei Luo,  Jun Li,  Jian Yang,  AAAI 2023   \n",
       "142                                                                                                               \n",
       "\n",
       "                                                                        ID/Link   \n",
       "0                                                                                \\\n",
       "1                                                                                 \n",
       "2                                                                                 \n",
       "3                                                                                 \n",
       "4                                                                                 \n",
       "..                                                                          ...   \n",
       "138                                                                               \n",
       "139  https://proceedings.mlr.press/v162/chandrasegaran22a/chandrasegaran22a.pdf   \n",
       "140                                                                               \n",
       "141                                            https://arxiv.org/abs/2211.16231   \n",
       "142                                                                               \n",
       "\n",
       "                                                         Source  \n",
       "0    https://github.com/DefangChen/Knowledge-Distillation-Paper  \n",
       "1    https://github.com/FLHonker/Awesome-Knowledge-Distillation  \n",
       "2    https://github.com/FLHonker/Awesome-Knowledge-Distillation  \n",
       "3    https://github.com/FLHonker/Awesome-Knowledge-Distillation  \n",
       "4    https://github.com/FLHonker/Awesome-Knowledge-Distillation  \n",
       "..                                                          ...  \n",
       "138  https://github.com/FLHonker/Awesome-Knowledge-Distillation  \n",
       "139     https://github.com/lhyfst/knowledge-distillation-papers  \n",
       "140  https://github.com/DefangChen/Knowledge-Distillation-Paper  \n",
       "141     https://github.com/lhyfst/knowledge-distillation-papers  \n",
       "142  https://github.com/DefangChen/Knowledge-Distillation-Paper  \n",
       "\n",
       "[143 rows x 6 columns]"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "awesome_nlp_paper_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "awesome_paper_df.to_excel('awesome_paper_df.xlsx')\n",
    "awesome_nlp_paper_df.to_excel('awesome_nlp_paper_df.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Github</b>\n",
    "<br>[DefangChen/Knowledge-Distillation-Paper](https://github.com/DefangChen/Knowledge-Distillation-Paper)\n",
    "<br>[FLHonker/Awesome-Knowledge-Distillation](https://github.com/FLHonker/Awesome-Knowledge-Distillation)\n",
    "<br>[lhyfst/knowledge-distillation-papers](https://github.com/lhyfst/knowledge-distillation-papers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
